{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d0bb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Confusion Matrix:\n",
      " [[1956   33]\n",
      " [   7    4]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9964    0.9834    0.9899      1989\n",
      "           1     0.1081    0.3636    0.1667        11\n",
      "\n",
      "    accuracy                         0.9800      2000\n",
      "   macro avg     0.5523    0.6735    0.5783      2000\n",
      "weighted avg     0.9915    0.9800    0.9854      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from glob import glob\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# ----------------------\n",
    "# SETTINGS & DATA LOAD\n",
    "# ----------------------\n",
    "ROOT_DIR = r'C:\\Users\\jgmad\\Research\\Ibn'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "summary_file, = glob(os.path.join(DATA_DIR, \"ZTFBTS_summary.csv\"))\n",
    "summary_data = pd.read_csv(summary_file)\n",
    "summary_data.replace('-', np.nan, inplace=True)\n",
    "\n",
    "DAYS_AFTER = 0\n",
    "param_file, = glob(os.path.join(DATA_DIR, f\"gp_params_SN_all{'_' + str(DAYS_AFTER) if DAYS_AFTER else ''}.csv\"))\n",
    "df = pd.read_csv(param_file)\n",
    "\n",
    "# ----------------------\n",
    "# INITIAL FILTERING\n",
    "# ----------------------\n",
    "try:\n",
    "    df = df.rename(columns={'oid':'supernova_name'})\n",
    "    df = df.drop(['oid_r','oid_g'], axis=1)\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "cols_to_convert = [c for c in df.columns if c not in ['supernova_name','Ibn']]\n",
    "\n",
    "# Convert them to float\n",
    "df[cols_to_convert] = df[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "lookup = dict(zip(summary_data['ZTFID'], summary_data['type'] == 'SN Ibn'))\n",
    "redshifts = dict(zip(summary_data['ZTFID'], summary_data['redshift']))\n",
    "\n",
    "df['Ibn'] = df['supernova_name'].map(lookup)\n",
    "df = df[df['Ibn'].notna()]\n",
    "\n",
    "df['redshift'] = df['supernova_name'].map(redshifts).astype(float)\n",
    "\n",
    "# Drop invalid redshift rows\n",
    "df = df[df['redshift'] > 0]\n",
    "\n",
    "# Features to use\n",
    "all_features = ['mean_g', 'mean_r', 'log_diagonal_short_r',\n",
    "       'log_diagonal_short_g', 'log_diagonal_long_r', 'log_diagonal_long_g',\n",
    "       'off_diagonal_short', 'off_diagonal_long', 'log_scale_long', 'log_scale_short'] + ['color_mean','color_at_peak','color_min_time','color_max_time'] + ['redshift']\n",
    "\n",
    "# Drop rows missing critical cut features\n",
    "df.replace(-9999, np.nan, inplace=True)\n",
    "cut_feats = ['redshift','mean_r','mean_g']\n",
    "df = df.dropna(subset=cut_feats)\n",
    "\n",
    "# ----------------------\n",
    "# TRAIN/TEST SPLIT\n",
    "# ----------------------\n",
    "full = df.reset_index(drop=True)\n",
    "unique_SN = full['supernova_name'].unique()\n",
    "SN_to_type = {sn: full.loc[full['supernova_name']==sn,'Ibn'].iat[0] for sn in unique_SN}\n",
    "types = [SN_to_type[sn] for sn in unique_SN]\n",
    "train_SN, test_SN = train_test_split(unique_SN, stratify=types, test_size=0.2, random_state=12282005)\n",
    "mask = full['supernova_name'].isin(train_SN)\n",
    "\n",
    "X_train_raw = full.loc[mask, all_features]\n",
    "y_train = full.loc[mask, 'Ibn'].astype(int)\n",
    "X_test_raw = full.loc[~mask, all_features]\n",
    "y_test = full.loc[~mask, 'Ibn'].astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# PIPELINE\n",
    "# ----------------------\n",
    "class CosmologyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cosmo):\n",
    "        self.cosmo = cosmo\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        dL = self.cosmo.luminosity_distance(X['redshift']).to('pc').value\n",
    "        '''mu = 5 * np.log10(dL) - 5\n",
    "        X['peak_mag_r'] -= mu\n",
    "        X['peak_mag_g'] -= mu\n",
    "        X['color'] = X['peak_mag_g'] - X['peak_mag_r']'''\n",
    "        return X\n",
    "\n",
    "'''preprocessor = ColumnTransformer([\n",
    "    ('num_imp', SimpleImputer(strategy='median', add_indicator=True), imputed_features),\n",
    "    ('pass', 'passthrough', other_features + ['color'])\n",
    "])'''\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.07,\n",
    "    'num_leaves': 26,\n",
    "    'max_depth': 4,\n",
    "    'min_child_samples': 84,\n",
    "    'reg_alpha': 0.266,\n",
    "    'reg_lambda': 0.093,\n",
    "    'subsample': 0.667,\n",
    "    'colsample_bytree': 0.665,\n",
    "    'random_state': 12282005,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    #('cosmo', CosmologyTransformer(cosmo=cosmo)),\n",
    "    #('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=12282005, sampling_strategy=0.93)),\n",
    "    ('clf', LGBMClassifier(**best_params))\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# TRAINING\n",
    "# ----------------------\n",
    "# Fit pipeline on training data\n",
    "# Prepare full labeled data\n",
    "X_all_raw = full[all_features]\n",
    "y_all = full['Ibn'].astype(int)\n",
    "pipeline.fit(X_train_raw, y_train)\n",
    "\n",
    "best_threshold = 0.0628\n",
    "\n",
    "'''# Save pipeline & threshold\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(pipeline, 'models/clf_pipeline.joblib')\n",
    "\n",
    "joblib.dump(best_threshold, 'models/best_threshold.pkl')'''\n",
    "\n",
    "# ----------------------\n",
    "# EVALUATION\n",
    "# ----------------------\n",
    "probs = pipeline.predict_proba(X_test_raw)[:, 1]\n",
    "pred = (probs >= best_threshold).astype(int)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58eba065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rise_slope_r', 'rise_slope_g', 'decline_slope_r', 'decline_slope_g',\n",
      "       'duration_g', 'duration_r', 'peak_epoch_g', 'peak_epoch_r',\n",
      "       'rise_time_g', 'rise_time_r', 'peak_mag_r', 'peak_mag_g', 'redshift',\n",
      "       'first_det_r', 'first_det_g', 'ndetection_g', 'ndetection_r'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f36519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10584 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['redshift'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    103\u001b[39m train_SN, test_SN = train_test_split(unique_SN,\n\u001b[32m    104\u001b[39m                                      stratify=[SN_to_type[sn] \u001b[38;5;28;01mfor\u001b[39;00m sn \u001b[38;5;129;01min\u001b[39;00m unique_SN],\n\u001b[32m    105\u001b[39m                                      test_size=\u001b[32m0.4\u001b[39m,\n\u001b[32m    106\u001b[39m                                      random_state=\u001b[32m12282005\u001b[39m)\n\u001b[32m    107\u001b[39m mask_train = df_labeled[\u001b[33m'\u001b[39m\u001b[33msupernova_name\u001b[39m\u001b[33m'\u001b[39m].isin(train_SN)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m X_train_raw = \u001b[43mdf_labeled\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    109\u001b[39m y_train     = df_labeled.loc[mask_train, \u001b[33m'\u001b[39m\u001b[33mIbn\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    110\u001b[39m X_test_raw  = df_labeled.loc[~mask_train, all_features]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m   1183\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._get_value(*key, takeable=\u001b[38;5;28mself\u001b[39m._takeable)\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1186\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[32m   1187\u001b[39m     axis = \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1377\u001b[39m, in \u001b[36m_LocIndexer._getitem_tuple\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_take_opportunity(tup):\n\u001b[32m   1375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_take(tup)\n\u001b[32m-> \u001b[39m\u001b[32m1377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1020\u001b[39m, in \u001b[36m_LocationIndexer._getitem_tuple_same_dim\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m com.is_null_slice(key):\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m retval = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m retval.ndim == \u001b[38;5;28mself\u001b[39m.ndim\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m   1418\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index with multidimensional key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1360\u001b[39m, in \u001b[36m_LocIndexer._getitem_iterable\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m   1359\u001b[39m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m keyarr, indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._reindex_with_indexers(\n\u001b[32m   1362\u001b[39m     {axis: [keyarr, indexer]}, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1363\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[39m, in \u001b[36m_LocIndexer._get_listlike_indexer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1555\u001b[39m ax = \u001b[38;5;28mself\u001b[39m.obj._get_axis(axis)\n\u001b[32m   1556\u001b[39m axis_name = \u001b[38;5;28mself\u001b[39m.obj._get_axis_name(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m keyarr, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['redshift'] not in index\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from glob import glob\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ----------------------\n",
    "# SETTINGS & DATA LOAD\n",
    "# ----------------------\n",
    "ROOT_DIR = r'C:\\Users\\jgmad\\Research\\Ibn'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "# Summary file contains labels and redshifts\n",
    "summary_file, = glob(os.path.join(DATA_DIR, \"ZTFBTS_summary.csv\"))\n",
    "summary_data = pd.read_csv(summary_file)\n",
    "summary_data.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# Parameter file (unlabeled + labeled combined)\n",
    "DAYS_AFTER = 0\n",
    "param_file, = glob(os.path.join(DATA_DIR, f\"gp_params_SN_all{'_' + str(DAYS_AFTER) if DAYS_AFTER else ''}.csv\"))\n",
    "df_full = pd.read_csv(param_file)\n",
    "\n",
    "# Rename identifier column to 'supernova_name'\n",
    "if 'oid' in df_full.columns:\n",
    "    df_full = df_full.rename(columns={'oid':'supernova_name'})\n",
    "elif 'ZTFID' in df_full.columns:\n",
    "    df_full = df_full.rename(columns={'ZTFID':'supernova_name'})\n",
    "\n",
    "# ----------------------\n",
    "# SEPARATE LABELED & UNLABELED\n",
    "# ----------------------\n",
    "# Map known SN Ibn labels from summary_data\n",
    "label_lookup = dict(zip(summary_data['ZTFID'], summary_data['type'] == 'SN Ibn'))\n",
    "df_full['Ibn'] = df_full['supernova_name'].map(label_lookup)\n",
    "type_dict = dict(zip(summary_data['ZTFID'], summary_data['type']))\n",
    "\n",
    "df_labeled   = df_full[~df_full['supernova_name'].map(type_dict).isnull()] # For now only labeled dataset\n",
    "df_unlabeled = df_full[df_full['supernova_name'].map(type_dict).isnull()]\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# SEPARATE LABELED & UNLABELED\n",
    "# ----------------------\n",
    "# Map known SN Ibn labels from summary_data\n",
    "label_lookup = dict(zip(summary_data['ZTFID'], summary_data['type'] == 'SN Ibn'))\n",
    "df_full['Ibn'] = df_full['supernova_name'].map(label_lookup)\n",
    "type_dict = dict(zip(summary_data['ZTFID'], summary_data['type']))\n",
    "\n",
    "df_labeled   = df_full[~df_full['supernova_name'].map(type_dict).isnull()] # For now only labeled dataset\n",
    "df_unlabeled = df_full[df_full['supernova_name'].map(type_dict).isnull()]\n",
    "print(len(df_labeled),len(df_unlabeled))\n",
    "# ----------------------\n",
    "# INITIAL FILTERING FUNCTION\n",
    "# ----------------------\n",
    "def filter_dataframe(df):\n",
    "    # Rename & drop oid columns if still present\n",
    "    try:\n",
    "        df = df.rename(columns={'oid':'supernova_name'})\n",
    "        df = df.drop(['oid_r','oid_g'], axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    # Map redshift\n",
    "    #red_lookup = dict(zip(summary_data['ZTFID'], summary_data['redshift']))\n",
    "    #df['redshift'] = df['supernova_name'].map(red_lookup).astype(float)\n",
    "\n",
    "    # Drop invalid or missing redshift\n",
    "    #df = df[df['redshift'] > 0]\n",
    "\n",
    "    # Replace magic missing values and drop on cut features\n",
    "    df.replace(-9999, np.nan, inplace=True)\n",
    "    #df = df.dropna(subset=['peak_mag_r','peak_mag_g'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply filtering to both labeled and unlabeled\n",
    "[df_labeled, df_unlabeled] = [filter_dataframe(sub) for sub in (df_labeled, df_unlabeled)]\n",
    "df_unlabeled\n",
    "\n",
    "# ----------------------\n",
    "# FEATURE LIST\n",
    "# ----------------------\n",
    "all_features = ['mean_g', 'mean_r', 'log_diagonal_short_r',\n",
    "       'log_diagonal_short_g', 'log_diagonal_long_r', 'log_diagonal_long_g',\n",
    "       'off_diagonal_short', 'off_diagonal_long', 'log_scale_long', 'log_scale_short'] + ['color_mean','color_at_peak','color_min_time','color_max_time'] + ['redshift']\n",
    "\n",
    "# ----------------------\n",
    "# TRAIN/TEST SPLIT (LABELED)\n",
    "# ----------------------\n",
    "unique_SN = df_labeled['supernova_name'].unique()\n",
    "SN_to_type = {sn: int(df_labeled.loc[df_labeled['supernova_name']==sn,'Ibn'].iloc[0]) for sn in unique_SN}\n",
    "train_SN, test_SN = train_test_split(unique_SN,\n",
    "                                     stratify=[SN_to_type[sn] for sn in unique_SN],\n",
    "                                     test_size=0.4,\n",
    "                                     random_state=12282005)\n",
    "mask_train = df_labeled['supernova_name'].isin(train_SN)\n",
    "X_train_raw = df_labeled.loc[mask_train, all_features]\n",
    "y_train     = df_labeled.loc[mask_train, 'Ibn'].astype(int)\n",
    "X_test_raw  = df_labeled.loc[~mask_train, all_features]\n",
    "y_test      = df_labeled.loc[~mask_train, 'Ibn'].astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# PIPELINE DEFINITION\n",
    "# ----------------------\n",
    "'''class CosmologyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cosmo_model):\n",
    "        self.cosmo = cosmo_model\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if 'redshift' not in X.columns:\n",
    "            X['color'] = X['peak_mag_g'] - X['peak_mag_r']\n",
    "            return X\n",
    "        dL = self.cosmo.luminosity_distance(X['redshift']).to('pc').value\n",
    "        mu = 5 * np.log10(dL) - 5\n",
    "        X['peak_mag_r'] -= mu\n",
    "        X['peak_mag_g'] -= mu\n",
    "        X['color'] = X['peak_mag_g'] - X['peak_mag_r']\n",
    "        return X'''\n",
    "\n",
    "'''preprocessor = ColumnTransformer([\n",
    "    ('imp', SimpleImputer(strategy='median', add_indicator=True), imputed_features),\n",
    "    ('pass', 'passthrough', other_features + ['color'])\n",
    "])'''\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.07,\n",
    "    'num_leaves': 26,\n",
    "    'max_depth': 4,\n",
    "    'min_child_samples': 84,\n",
    "    'reg_alpha': 0.266,\n",
    "    'reg_lambda': 0.093,\n",
    "    'subsample': 0.667,\n",
    "    'colsample_bytree': 0.665,\n",
    "    'random_state': 12282005,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    #('cosmo', CosmologyTransformer(cosmo)),\n",
    "    #('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=12282005, sampling_strategy=0.93)),\n",
    "    ('clf', LGBMClassifier(**best_params))\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# TRAINING & EVALUATION\n",
    "# ----------------------\n",
    "pipeline.fit(X_train_raw, y_train)\n",
    "probs_test = pipeline.predict_proba(X_test_raw)[:,1]\n",
    "threshold  = 0.0628\n",
    "pred_test  = (probs_test >= threshold).astype(int)\n",
    "print(\"=== Labeled Test Set Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred_test))\n",
    "print(classification_report(y_test, pred_test, digits=4))\n",
    "\n",
    "# Save model and threshold\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(pipeline, 'models/clf_pipeline.joblib')\n",
    "joblib.dump(threshold, 'models/best_threshold.pkl')\n",
    "\n",
    "# ----------------------\n",
    "# INFERENCE ON UNLABELED\n",
    "# ----------------------\n",
    "X_unlab = df_unlabeled[all_features]\n",
    "print(X_unlab)\n",
    "probs_unlab = pipeline.predict_proba(X_unlab)[:,1]\n",
    "labels_unlab = (probs_unlab >= threshold).astype(int)\n",
    "\n",
    "df_unlabeled['Ibn_prob'] = probs_unlab\n",
    "df_unlabeled['Ibn_pred'] = labels_unlab\n",
    "df_unlabeled.to_csv(os.path.join(DATA_DIR, 'SN_unlabeled_with_predictions.csv'), index=False)\n",
    "print(\"Unlabeled predictions saved to SN_unlabeled_with_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      supernova_name  decline_slope_g  decline_slope_r  duration_g  \\\n",
      "5268    ZTF21aakylsb         0.121511         0.128678    9.044167   \n",
      "5894    ZTF21aaxbidh         0.124035         0.098193   13.004074   \n",
      "12029   ZTF22aadgetr         0.088476         0.107720   12.987847   \n",
      "\n",
      "       duration_r filt_g filt_r   first_det_g   first_det_r  last_nondet_g  \\\n",
      "5268     6.926620      g      r  59260.173611  59260.239699            NaN   \n",
      "5894    12.995636      g      r  59325.443137  59325.481667            NaN   \n",
      "12029   12.948113      g      r  59670.496690  59670.476748            NaN   \n",
      "\n",
      "       ...  rise_slope_r  rise_time_flag_g  rise_time_flag_r  rise_time_g  \\\n",
      "5268   ...           NaN               NaN               NaN          NaN   \n",
      "5894   ...           NaN               NaN               NaN          NaN   \n",
      "12029  ...           NaN               NaN               NaN          NaN   \n",
      "\n",
      "       rise_time_r  s0_g  s0_r    Ibn  Ibn_prob  Ibn_pred  \n",
      "5268           NaN   NaN   NaN  False  0.999856         1  \n",
      "5894           NaN   NaN   NaN  False  0.999717         1  \n",
      "12029          NaN   NaN   NaN  False  0.999650         1  \n",
      "\n",
      "[3 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_unlabeled[df_unlabeled['Ibn_prob'] > 0.99965])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beb9c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEND ALEX UNCLASSIFIED \n",
    "df_unlabeled = df_unlabeled.reset_index(drop=True)\n",
    "df_unlabeled[['supernova_name']].to_csv('unlabeled_in_parameters.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b7aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibn_gp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
