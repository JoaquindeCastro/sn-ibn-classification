{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5d0bb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9922480620155039\n",
      "Confusion Matrix:\n",
      " [[1657   12]\n",
      " [   1    7]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9994    0.9928    0.9961      1669\n",
      "           1     0.3684    0.8750    0.5185         8\n",
      "\n",
      "    accuracy                         0.9922      1677\n",
      "   macro avg     0.6839    0.9339    0.7573      1677\n",
      "weighted avg     0.9964    0.9922    0.9938      1677\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from glob import glob\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# ----------------------\n",
    "# SETTINGS & DATA LOAD\n",
    "# ----------------------\n",
    "ROOT_DIR = r'C:\\Users\\jgmad\\Research\\Ibn'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "summary_file, = glob(os.path.join(DATA_DIR, \"ZTFBTS_summary.csv\"))\n",
    "summary_data = pd.read_csv(summary_file)\n",
    "summary_data.replace('-', np.nan, inplace=True)\n",
    "\n",
    "DAYS_AFTER = 0\n",
    "param_file, = glob(os.path.join(DATA_DIR, f\"SN_interpretable_params{'_'+str(DAYS_AFTER) if DAYS_AFTER else ''}.csv\"))\n",
    "df = pd.read_csv(param_file)\n",
    "\n",
    "# ----------------------\n",
    "# INITIAL FILTERING\n",
    "# ----------------------\n",
    "try:\n",
    "    df = df.rename(columns={'oid':'supernova_name'})\n",
    "    df = df.drop(['oid_r','oid_g'], axis=1)\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "df['first_det_r'] = df['first_det_r'].astype(float)\n",
    "df['first_det_g'] = df['first_det_g'].astype(float)\n",
    "\n",
    "lookup = dict(zip(summary_data['ZTFID'], summary_data['type'] == 'SN Ibn'))\n",
    "redshifts = dict(zip(summary_data['ZTFID'], summary_data['redshift']))\n",
    "\n",
    "df['Ibn'] = df['supernova_name'].map(lookup)\n",
    "df = df[df['Ibn'].notna()]\n",
    "\n",
    "df['redshift'] = df['supernova_name'].map(redshifts).astype(float)\n",
    "\n",
    "# Drop invalid redshift rows\n",
    "df = df[df['redshift'] > 0]\n",
    "\n",
    "# Features to use\n",
    "slope_features = ['rise_slope_r','rise_slope_g','decline_slope_r','decline_slope_g']\n",
    "imputed_features = slope_features + ['duration_g','duration_r','peak_epoch_g','peak_epoch_r','rise_time_g','rise_time_r']\n",
    "other_features = ['peak_mag_r','peak_mag_g','redshift','first_det_r','first_det_g','ndetection_g','ndetection_r']\n",
    "all_features = imputed_features + other_features\n",
    "\n",
    "# Drop rows missing critical cut features\n",
    "df.replace(-9999, np.nan, inplace=True)\n",
    "cut_feats = ['peak_mag_r','peak_mag_g','redshift']\n",
    "df = df.dropna(subset=cut_feats)\n",
    "\n",
    "# ----------------------\n",
    "# TRAIN/TEST SPLIT\n",
    "# ----------------------\n",
    "full = df.reset_index(drop=True)\n",
    "unique_SN = full['supernova_name'].unique()\n",
    "SN_to_type = {sn: full.loc[full['supernova_name']==sn,'Ibn'].iat[0] for sn in unique_SN}\n",
    "types = [SN_to_type[sn] for sn in unique_SN]\n",
    "train_SN, test_SN = train_test_split(unique_SN, stratify=types, test_size=0.2, random_state=12282005)\n",
    "mask = full['supernova_name'].isin(train_SN)\n",
    "\n",
    "X_train_raw = full.loc[mask, all_features]\n",
    "y_train = full.loc[mask, 'Ibn'].astype(int)\n",
    "X_test_raw = full.loc[~mask, all_features]\n",
    "y_test = full.loc[~mask, 'Ibn'].astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# PIPELINE\n",
    "# ----------------------\n",
    "class CosmologyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cosmo):\n",
    "        self.cosmo = cosmo\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        dL = self.cosmo.luminosity_distance(X['redshift']).to('pc').value\n",
    "        mu = 5 * np.log10(dL) - 5\n",
    "        X['peak_mag_r'] -= mu\n",
    "        X['peak_mag_g'] -= mu\n",
    "        X['color'] = X['peak_mag_g'] - X['peak_mag_r']\n",
    "        return X\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_imp', SimpleImputer(strategy='median', add_indicator=True), imputed_features),\n",
    "    ('pass', 'passthrough', other_features + ['color'])\n",
    "])\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.07,\n",
    "    'num_leaves': 26,\n",
    "    'max_depth': 4,\n",
    "    'min_child_samples': 84,\n",
    "    'reg_alpha': 0.266,\n",
    "    'reg_lambda': 0.093,\n",
    "    'subsample': 0.667,\n",
    "    'colsample_bytree': 0.665,\n",
    "    'random_state': 12282005,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('cosmo', CosmologyTransformer(cosmo=cosmo)),\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=12282005, sampling_strategy=0.93)),\n",
    "    ('clf', LGBMClassifier(**best_params))\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# TRAINING\n",
    "# ----------------------\n",
    "# Fit pipeline on training data\n",
    "# Prepare full labeled data\n",
    "X_all_raw = full[all_features]\n",
    "y_all = full['Ibn'].astype(int)\n",
    "pipeline.fit(X_train_raw, y_train)\n",
    "\n",
    "best_threshold = 0.0628\n",
    "\n",
    "'''# Save pipeline & threshold\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(pipeline, 'models/clf_pipeline.joblib')\n",
    "\n",
    "joblib.dump(best_threshold, 'models/best_threshold.pkl')'''\n",
    "\n",
    "# ----------------------\n",
    "# EVALUATION\n",
    "# ----------------------\n",
    "probs = pipeline.predict_proba(X_test_raw)[:, 1]\n",
    "pred = (probs >= best_threshold).astype(int)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58eba065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rise_slope_r', 'rise_slope_g', 'decline_slope_r', 'decline_slope_g',\n",
      "       'duration_g', 'duration_r', 'peak_epoch_g', 'peak_epoch_r',\n",
      "       'rise_time_g', 'rise_time_r', 'peak_mag_r', 'peak_mag_g', 'redshift',\n",
      "       'first_det_r', 'first_det_g', 'ndetection_g', 'ndetection_r'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f36519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8732 3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\jgmad\\Research\\Ibn\\ibn_gp_venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Labeled Test Set Performance ===\n",
      "Accuracy: 0.9919839679358717\n",
      "Confusion Matrix:\n",
      " [[3449   27]\n",
      " [   1   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9922    0.9960      3476\n",
      "           1     0.3721    0.9412    0.5333        17\n",
      "\n",
      "    accuracy                         0.9920      3493\n",
      "   macro avg     0.6859    0.9667    0.7646      3493\n",
      "weighted avg     0.9967    0.9920    0.9937      3493\n",
      "\n",
      "       rise_slope_r  rise_slope_g  ...  ndetection_g  ndetection_r\n",
      "6         -0.004496     -0.000640  ...             8             8\n",
      "12              NaN           NaN  ...            11            11\n",
      "13         0.015177      0.040738  ...             8             8\n",
      "14         0.106782      0.077486  ...             5             8\n",
      "17         0.039143      0.050825  ...            11            18\n",
      "...             ...           ...  ...           ...           ...\n",
      "12169      0.023857      0.000387  ...             7             8\n",
      "12175      0.051351      0.123391  ...             5             4\n",
      "12178           NaN           NaN  ...             6             6\n",
      "12180      0.108439      0.125383  ...            15            13\n",
      "12181      0.026347           NaN  ...             5             7\n",
      "\n",
      "[3450 rows x 16 columns]\n",
      "Unlabeled predictions saved to SN_unlabeled_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from glob import glob\n",
    "from astropy.cosmology import Planck18 as cosmo\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ----------------------\n",
    "# SETTINGS & DATA LOAD\n",
    "# ----------------------\n",
    "ROOT_DIR = r'C:\\Users\\jgmad\\Research\\Ibn'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "# Summary file contains labels and redshifts\n",
    "summary_file, = glob(os.path.join(DATA_DIR, \"ZTFBTS_summary.csv\"))\n",
    "summary_data = pd.read_csv(summary_file)\n",
    "summary_data.replace('-', np.nan, inplace=True)\n",
    "\n",
    "# Parameter file (unlabeled + labeled combined)\n",
    "DAYS_AFTER = 0\n",
    "param_file, = glob(os.path.join(DATA_DIR, f\"SN_interpretable_params{'_'+str(DAYS_AFTER) if DAYS_AFTER else ''}.csv\"))\n",
    "df_full = pd.read_csv(param_file)\n",
    "\n",
    "# Rename identifier column to 'supernova_name'\n",
    "if 'oid' in df_full.columns:\n",
    "    df_full = df_full.rename(columns={'oid':'supernova_name'})\n",
    "elif 'ZTFID' in df_full.columns:\n",
    "    df_full = df_full.rename(columns={'ZTFID':'supernova_name'})\n",
    "\n",
    "# ----------------------\n",
    "# SEPARATE LABELED & UNLABELED\n",
    "# ----------------------\n",
    "# Map known SN Ibn labels from summary_data\n",
    "label_lookup = dict(zip(summary_data['ZTFID'], summary_data['type'] == 'SN Ibn'))\n",
    "df_full['Ibn'] = df_full['supernova_name'].map(label_lookup)\n",
    "type_dict = dict(zip(summary_data['ZTFID'], summary_data['type']))\n",
    "\n",
    "df_labeled   = df_full[~df_full['supernova_name'].map(type_dict).isnull()] # For now only labeled dataset\n",
    "df_unlabeled = df_full[df_full['supernova_name'].map(type_dict).isnull()]\n",
    "print(len(df_labeled),len(df_unlabeled))\n",
    "# ----------------------\n",
    "# INITIAL FILTERING FUNCTION\n",
    "# ----------------------\n",
    "def filter_dataframe(df):\n",
    "    # Rename & drop oid columns if still present\n",
    "    try:\n",
    "        df = df.rename(columns={'oid':'supernova_name'})\n",
    "        df = df.drop(['oid_r','oid_g'], axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    # Ensure numeric types\n",
    "    df['first_det_r'] = df['first_det_r'].astype(float)\n",
    "    df['first_det_g'] = df['first_det_g'].astype(float)\n",
    "\n",
    "    # Map redshift\n",
    "    #red_lookup = dict(zip(summary_data['ZTFID'], summary_data['redshift']))\n",
    "    #df['redshift'] = df['supernova_name'].map(red_lookup).astype(float)\n",
    "\n",
    "    # Drop invalid or missing redshift\n",
    "    #df = df[df['redshift'] > 0]\n",
    "\n",
    "    # Replace magic missing values and drop on cut features\n",
    "    df.replace(-9999, np.nan, inplace=True)\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    df['peak_mag_r'] = imputer.fit_transform(df[['peak_mag_r']]).flatten()\n",
    "    df['peak_mag_g'] = imputer.fit_transform(df[['peak_mag_g']]).flatten()\n",
    "    #df = df.dropna(subset=['peak_mag_r','peak_mag_g'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply filtering to both labeled and unlabeled\n",
    "[df_labeled, df_unlabeled] = [filter_dataframe(sub) for sub in (df_labeled, df_unlabeled)]\n",
    "df_unlabeled\n",
    "\n",
    "# ----------------------\n",
    "# FEATURE LIST\n",
    "# ----------------------\n",
    "slope_features   = ['rise_slope_r','rise_slope_g','decline_slope_r','decline_slope_g']\n",
    "imputed_features = slope_features + ['duration_g','duration_r','peak_epoch_g','peak_epoch_r','rise_time_g','rise_time_r']+['peak_mag_r', 'peak_mag_g','first_det_g', 'first_det_r']\n",
    "other_features   = ['ndetection_g','ndetection_r']\n",
    "all_features     = imputed_features + other_features\n",
    "\n",
    "# ----------------------\n",
    "# TRAIN/TEST SPLIT (LABELED)\n",
    "# ----------------------\n",
    "unique_SN = df_labeled['supernova_name'].unique()\n",
    "SN_to_type = {sn: int(df_labeled.loc[df_labeled['supernova_name']==sn,'Ibn'].iloc[0]) for sn in unique_SN}\n",
    "train_SN, test_SN = train_test_split(unique_SN,\n",
    "                                     stratify=[SN_to_type[sn] for sn in unique_SN],\n",
    "                                     test_size=0.4,\n",
    "                                     random_state=12282005)\n",
    "mask_train = df_labeled['supernova_name'].isin(train_SN)\n",
    "X_train_raw = df_labeled.loc[mask_train, all_features]\n",
    "y_train     = df_labeled.loc[mask_train, 'Ibn'].astype(int)\n",
    "X_test_raw  = df_labeled.loc[~mask_train, all_features]\n",
    "y_test      = df_labeled.loc[~mask_train, 'Ibn'].astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# PIPELINE DEFINITION\n",
    "# ----------------------\n",
    "class CosmologyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cosmo_model):\n",
    "        self.cosmo = cosmo_model\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if 'redshift' not in X.columns:\n",
    "            X['color'] = X['peak_mag_g'] - X['peak_mag_r']\n",
    "            return X\n",
    "        dL = self.cosmo.luminosity_distance(X['redshift']).to('pc').value\n",
    "        mu = 5 * np.log10(dL) - 5\n",
    "        X['peak_mag_r'] -= mu\n",
    "        X['peak_mag_g'] -= mu\n",
    "        X['color'] = X['peak_mag_g'] - X['peak_mag_r']\n",
    "        return X\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('imp', SimpleImputer(strategy='median', add_indicator=True), imputed_features),\n",
    "    ('pass', 'passthrough', other_features + ['color'])\n",
    "])\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.07,\n",
    "    'num_leaves': 26,\n",
    "    'max_depth': 4,\n",
    "    'min_child_samples': 84,\n",
    "    'reg_alpha': 0.266,\n",
    "    'reg_lambda': 0.093,\n",
    "    'subsample': 0.667,\n",
    "    'colsample_bytree': 0.665,\n",
    "    'random_state': 12282005,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('cosmo', CosmologyTransformer(cosmo)),\n",
    "    ('prep', preprocessor),\n",
    "    ('smote', SMOTE(random_state=12282005, sampling_strategy=0.93)),\n",
    "    ('clf', LGBMClassifier(**best_params))\n",
    "])\n",
    "\n",
    "# ----------------------\n",
    "# TRAINING & EVALUATION\n",
    "# ----------------------\n",
    "pipeline.fit(X_train_raw, y_train)\n",
    "probs_test = pipeline.predict_proba(X_test_raw)[:,1]\n",
    "threshold  = 0.0628\n",
    "pred_test  = (probs_test >= threshold).astype(int)\n",
    "print(\"=== Labeled Test Set Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred_test))\n",
    "print(classification_report(y_test, pred_test, digits=4))\n",
    "\n",
    "# Save model and threshold\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(pipeline, 'models/clf_pipeline.joblib')\n",
    "joblib.dump(threshold, 'models/best_threshold.pkl')\n",
    "\n",
    "# ----------------------\n",
    "# INFERENCE ON UNLABELED\n",
    "# ----------------------\n",
    "X_unlab = df_unlabeled[all_features]\n",
    "print(X_unlab)\n",
    "probs_unlab = pipeline.predict_proba(X_unlab)[:,1]\n",
    "labels_unlab = (probs_unlab >= threshold).astype(int)\n",
    "\n",
    "df_unlabeled['Ibn_prob'] = probs_unlab\n",
    "df_unlabeled['Ibn_pred'] = labels_unlab\n",
    "df_unlabeled.to_csv(os.path.join(DATA_DIR, 'SN_unlabeled_with_predictions.csv'), index=False)\n",
    "print(\"Unlabeled predictions saved to SN_unlabeled_with_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      supernova_name  decline_slope_g  decline_slope_r  duration_g  \\\n",
      "5268    ZTF21aakylsb         0.121511         0.128678    9.044167   \n",
      "5894    ZTF21aaxbidh         0.124035         0.098193   13.004074   \n",
      "12029   ZTF22aadgetr         0.088476         0.107720   12.987847   \n",
      "\n",
      "       duration_r filt_g filt_r   first_det_g   first_det_r  last_nondet_g  \\\n",
      "5268     6.926620      g      r  59260.173611  59260.239699            NaN   \n",
      "5894    12.995636      g      r  59325.443137  59325.481667            NaN   \n",
      "12029   12.948113      g      r  59670.496690  59670.476748            NaN   \n",
      "\n",
      "       ...  rise_slope_r  rise_time_flag_g  rise_time_flag_r  rise_time_g  \\\n",
      "5268   ...           NaN               NaN               NaN          NaN   \n",
      "5894   ...           NaN               NaN               NaN          NaN   \n",
      "12029  ...           NaN               NaN               NaN          NaN   \n",
      "\n",
      "       rise_time_r  s0_g  s0_r    Ibn  Ibn_prob  Ibn_pred  \n",
      "5268           NaN   NaN   NaN  False  0.999856         1  \n",
      "5894           NaN   NaN   NaN  False  0.999717         1  \n",
      "12029          NaN   NaN   NaN  False  0.999650         1  \n",
      "\n",
      "[3 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_unlabeled[df_unlabeled['Ibn_prob'] > 0.99965])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beb9c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEND ALEX UNCLASSIFIED \n",
    "df_unlabeled = df_unlabeled.reset_index(drop=True)\n",
    "df_unlabeled[['supernova_name']].to_csv('unlabeled_in_parameters.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472b7aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supernova_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZTF25aafocmy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZTF21abkqvdo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZTF19aafmjfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZTF19acbkanq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZTF20acwyicy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>ZTF23aamzrto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>ZTF22abvtvmc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>ZTF20aatzcxk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>ZTF22abnawii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>ZTF21aalepvi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3450 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     supernova_name\n",
       "0      ZTF25aafocmy\n",
       "1      ZTF21abkqvdo\n",
       "2      ZTF19aafmjfw\n",
       "3      ZTF19acbkanq\n",
       "4      ZTF20acwyicy\n",
       "...             ...\n",
       "3445   ZTF23aamzrto\n",
       "3446   ZTF22abvtvmc\n",
       "3447   ZTF20aatzcxk\n",
       "3448   ZTF22abnawii\n",
       "3449   ZTF21aalepvi\n",
       "\n",
       "[3450 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('unlabeled_in_parameters.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864a7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.read_csv('data/ZTFBTS_summary.csv')\n",
    "\n",
    "names = df['supernova_name'].tolist()\n",
    "\n",
    "N = z[z['ZTFID'].isin(names)][['ZTFID','RA','Dec']]\n",
    "\n",
    "N.to_csv('unlabeled_in_parameters.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d769f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibn_gp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
